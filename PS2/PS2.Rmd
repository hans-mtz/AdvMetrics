---
title: "Advanced Metrics"
subtitle: "Problem Set 2: Maximization"
author: "Hans Martinez"
date: "`r format(Sys.time(),'%b %m %Y')`"
output: 
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
load("ps2.RData")
```

The code and the report can be found in my [github repo](https://github.com/hans-mtz/AdvMetrics/tree/master/PS2)

### MLE (Probit)

1. For the first question, I programmed the routine to estimate a probit model by MLE. I used the `CDF_Normal`, `PDF_Normal` and `BFGS` routines of the `Probability` and `Minimization` modules. Whenever the routine evaluated $\Phi(x'\beta)$, I used $\mu=0$ and $\sigma=1$, because $U_I \sim  N(0,1)$. The coefficients are displayed in row 1 of the results table. To compare, the results of estimating the probit in R are the following:

```{r, results='markup'}

# probit <- glm(V4~V2+V3, family = binomial(link=probit),data=data)
summary(probit)
```



2. For the second question, according to Nail's notes (take it with caution), $n^{1/2}(\hat{\theta}_{MLE}-\theta_0)\sim N(0,B^{-1})$, where in the case of probit
$$
B=E\left[xx'\frac{\phi(-x'\beta)^2}{\Phi(-x'\beta)\Phi(x'\beta)} \right]
$$ 
To invert the variance-covariance matrix $B$, I used the Cholesky factorization using intel-LAPACK routine `POTRF` and `POTRI`. I tried using the `Matrix_Inverse` and `Matrix_Inverse_symmetric` provided in the `Matrix` module but I was getting negative variances for some estimates. Using the Cholesky factorization, I could replicate the exact estimates as the `R` intrinsic program. The standard errors are shown in the table row 2.

3. Lastly, I bootstrapped the estimates 100 times. I used sampling from the uniform distribution and Halton sequences, by using`Sample_Uniform` and `Halton` from the `random` module, respectively. I report the unbiased bootstrapped estimators in the the table. Namely, $\tilde{\theta}=2\hat{\theta}-\bar{\hat{\theta^\star}}$. Rows 3 to 6 display the results.
Results are very close. Considering the standard errors, they are not significantly different from one another.

```{r, echo=FALSE, warning=FALSE}

# t <- as.numeric(res_m[2:7,])
knitr::kable(res_m[2:7,], col.names = nom, digits = 5, caption = "MLE Probit")
```


